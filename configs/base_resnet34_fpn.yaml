model:
  task: detection
  backbone:
    name: resnet34
    pretrained: True

  neck:
    name: fpn    # simple or fpn
    upsample_channels: [256, 128, 64]
    upsample_type: nearest    # conv_transpose, bilinear, nearest
    conv_type: normal         # normal, separable, dcn
    weighted_fusion: False    # True or False
      
  output_heads:
    heatmap:
      num_classes: 1
      init_bias: -2.19
      target_method: cornernet         # cornernet or ttfnet
      loss_function: cornernet_focal   # cornernet or quality (gfocal)
      loss_weight: 1

    box_2d:
      init_bias: 10
      loss_function: giou       # iou, giou, l1, or smooth_l1
      loss_weight: 5

  optimizer:           # mmdetection
    name: ADAM          # any optimizers from torch.optim
    params:
      lr: 0.02
      momentum: 0.9
      weight_decay: 0.0001

  lr_scheduler:
    name: OneCycleLR    # any lr_scheduler from torch.optim.lr_scheduler
    params:
      max_lr: 0.02

data:
  train:
    dataset:
      type: coco
      data_dir: /home/shiva/data/centernet_test/
      split: train2017

      # any transformations from Albumentation
      # augmentations used in CenterNet paper
      # https://github.com/xingyizhou/CenterNet/blob/master/src/lib/utils/image.py#L222
      # they also used PCA augmentation, but didn't mention in their paper
      transforms:
        - name: HorizontalFlip
          params:
            p: 0.5
        - name: RandomResizedCrop
          params:
            height: 512
            width: 512
        - name: ColorJitter
          params:
            brightness: 0.4
            contrast: 0.4
            saturation: 0.4
  
    dataloader:
      batch_size: 10
      num_workers: 8
      shuffle: True
      pin_memory: True

  validation:
    dataset:
      type: coco
      data_dir: /home/shiva/data/centernet_test/
      split: val2017

      transforms:
        - name: Resize
          params:
            width: 512
            height: 512
    
    dataloader:
      batch_size: 10
      num_workers: 8
      shuffle: False
      pin_memory: True
  

# pass to Lightning Trainer
trainer:
  gpus: 1
  precision: 16
  max_epochs: 30
  val_check_interval: 1.0
  benchmark: True
  gradient_clip_val: 35     # mmdetection

  # logger:
  #   name: WandbLogger     # PyTorch Lightning logger e.g. TensorboardLogger, WandbLogger
  #   params:
  #     project: detection
  #     log_model: True

  callbacks:
    - class_path: ModelCheckpoint
      params:
        monitor: val/AP
        mode: max
        save_last: True

    - class_path: LearningRateMonitor
      params:
        logging_interval: step
    
    - class_path: LogImageCallback
      params:
        n_epochs: 5
